install.packages("swirl")
library(mtcars)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
summary(fit)
dfbetas(fit)
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit)
?factor
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl), data = mtcars)
fit2$coefficients[3]
summary(fit1)
summary(fit2)
fit2$coefficients
fit2$coefficients[3]
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
fit1 <- lm(mpg ~ cyl + wt, data = mtcars)
summarry(fit1)
summary(fit1)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
summary(fit1)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
summary(fit2)
compare <- anova(fit1, fit2)
compare$Pr
anova(fit1, fit2)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl), data = mtcars)
fit2$coefficients[3]
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
?I()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
package.install("pgmm")
install.packages("pgmm")
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
library(randomForest)
#Fit a classification tree where Area is the outcome variable.
# Then predict the value of area for the following data frame using the tree command with all defaults
model <- train(Area ~ ., data = olive, method = "rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
b
?order
?varImp
varImpPlot(a)
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install.packages(devtools)
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install.packages("shiny")
library(shiny)
source('~/Shiny/DDP/server.r')
source('~/Shiny/DDP/ui.R')
runExample("01_hello")
setwd("~/PracticalMacinelearning")
library(caret)
training<-read.csv("pml-training.csv", na.strings=c("#DIV/0!"))
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|new_window", colnames(data))
data <- data[,!badCols]
return(data)
rm(data)
}
training<-headCleaner(training)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
inTrain = createDataPartition(y = training$classe, p = 0.6, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(training$classe ~ ., method = "glm", data = training)
modelFit <- train(training$classe ~ ., method = "glm", data = training[1:200,])
modelFit <- train(training$classe ~ ., method = "glm", data = training[1:2000,])
head(training)
training<-read.csv("pml-training.csv", na.strings=c("#DIV/0!"))
training<-headCleaner(training)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
training   <-  training[,Keep]
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
inTrain = createDataPartition(y = training$classe, p = 0.6, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(training$classe ~ ., method = "glm", data = training[1:2000,])
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|num_window|new_window", colnames(data))
data <- data[,!badCols]
return(data)
rm(data)
}
training<-read.csv("pml-training.csv", na.strings=c("#DIV/0!"))
training<-headCleaner(training)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
inTrain = createDataPartition(y = training$classe, p = 0.6, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(training$classe ~ ., method = "glm", data = training[1:2000,])
wm<-training[1:300,]
colSums(is.na(wm))
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|new_window", colnames(data))
data <- data[,!badCols]
data <- data[, (colSums(is.na(data)) == 0)]
return(data)
rm(data)
}
training<-headCleaner(training)
training<-headCleaner(training)
training<-read.csv("pml-training.csv")
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|new_window", colnames(data))
data <- data[,!badCols]
data <- data[, (colSums(is.na(data)) == 0)]
return(data)
rm(data)
}
training<-headCleaner(training)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
inTrain = createDataPartition(y = training$classe, p = 0.6, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
training = training[inTrain, ]
modelFit <- train(training$classe ~ ., method = "glm", data = training[1:2000,])
modelFit <- train(training$classe ~ ., method = "rpart", data = training[1:2000,])
modelFit <- train(classe ~ ., method = "rpart", data = training[1:2000,])
modelFit <- train(classe ~ ., method = "rf", data = training[1:2000,])
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(classe ~ ., method = "rf", data = training[1:2000,])
modelFit <- train(classe ~ ., method = "rf", data = training[1:200,])
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,],
trControl = trainControl(method = "cv", number = 4))
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,],
trControl = trainControl(method = "cv", number = 10))
training<-read.csv("pml-training.csv",na.strings=c("#DIV/0!") )
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|new_window", colnames(data))
data <- data[,!badCols]
data <- data[, (colSums(is.na(data)) == 0)]
return(data)
rm(data)
}
training<-headCleaner(training)
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,],
trControl = trainControl(method = "cv", number = 10))
modelFit <- train(classe ~ ., method = "glm",
data = training[1:200,])
summary(training$classe)
training[1:200,]
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
training<-read.csv("pml-training.csv",na.strings=c("#DIV/0!","NA") )
training<-headCleaner(training)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.8*nrow(training)))
training   <-  training[,Keep]
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(classe ~ ., method = "glm",
data = training[1:200,])
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,])
training<-read.csv("pml-training.csv",na.strings=c("#DIV/0!","NA","") )
training<-headCleaner(training)
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,])
model <- randomForest(classe~.,data=training[1:100,])
?type
type(training$classe)
type.training$classe
training$classe->x
x
model <- randomForest(training$classe~.,data=training[1:100,])
training$num_window
summary(training$num_window)
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,])
pml_CSV <- read.csv(txt_file, header=TRUE, sep=",", na.strings=c("NA",""))
pml_CSV <- read.csv("pml-training.csv", header=TRUE, sep=",", na.strings=c("NA",""))
pml_CSV <- pml_CSV[,-1]
inTrain = createDataPartition(pml_CSV$classe, p=0.60, list=FALSE)
training = pml_CSV[inTrain,]
validating = pml_CSV[-inTrain,]
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training)))
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]
model <- randomForest(classe~.,data=training)
print(model)
modelFit <- train(classe ~ ., method = "rf",
data = training[1:200,])
mo
modelFit <- train(classe ~ ., method = "rpart",
data = training[1:200,])
modelFit <- train(classe ~ ., method = "rtree",
data = training[1:200,])
modelFit <- train(classe ~ ., method = "glm",
data = training[1:200,])
model <- lm(classe~.,data=training)
model <- glm(classe~.,data=training)
training<-read.csv("pml-training.csv",na.strings=c("#DIV/0!","NA","") )
headCleaner <- function(data){
badCols = grepl("X|user_name|timestamp|new_window", colnames(data))
data <- data[,!badCols]
data <- data[, (colSums(is.na(data)) == 0)]
return(data)
rm(data)
}
training<-headCleaner(training)
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
inTrain = createDataPartition(pml_CSV$classe, p=0.60, list=FALSE)
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]
model <- randomForest(classe~.,data=training)
print(model)
inTrain = createDataPartition(y = training$classe, p = 0.4, list = FALSE)
validating = training[-inTrain, ]
training = training[inTrain, ]
importance(model)
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)
pml_CSV <- read.csv("pml-training.csv", header=TRUE, sep=",", na.strings=c("NA",""))
pml_CSV <- pml_CSV[,-1]
inTrain = createDataPartition(pml_CSV$classe, p=0.60, list=FALSE)
training = pml_CSV[inTrain,]
validating = pml_CSV[-inTrain,]
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training)))
model <- randomForest(classe~.,data=training)
importance(model)
print(model)
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)
training<-headCleaner(training)
model <- randomForest(classe~.,data=training)
importance(model)
print(model)
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)
rf_model<-train(classe~.,data=training,method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,allowParallel=TRUE)
